<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta name="generator" content="plasTeX" />
<meta content="text/html; charset=utf-8" http-equiv="content-type" />

<title></title>



<link rel="stylesheet" href="styles/styles.css" />
</head>
<body>

<div class="navigation">
<table cellspacing="2" cellpadding="0" width="100%">
<tr>

<td><img border="0" alt="" src="icons/blank.gif" width="32" height="32" /></td>

<td><img border="0" alt="" src="icons/blank.gif" width="32" height="32" /></td>

<td><img border="0" alt="" src="icons/blank.gif" width="32" height="32" /></td>
<td class="navtitle" align="center">Estimation Algorithms</td>
<td><a href="index.html" title="Table of Contents"><img border="0" alt="" src="icons/contents.gif" width="32" height="32" /></a></td>


<td><img border="0" alt="" src="icons/blank.gif" width="32" height="32" /></td>
<td><img border="0" alt="" src="icons/blank.gif" width="32" height="32" /></td>
</tr>
</table>
</div>



<div><div class="titlepage">
<h1>Estimation Algorithms</h1>



</div><p>This document describes two methods for estimating the total size of a population given a collection of samples taken with replacement. The first is described in <a href="https://www.jstor.org/stable/25750547?seq=1">Cuthbert, Michael Scott. 2009. “Tipping the Iceberg: Missing Italian Polyphony from the Age of Schism,” <i class="itshape">Musica Disciplina</i> 54: 39–74</a>. The second is described in <a href="https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1998.10474118">Boneh, Shahar, Arnon Boneh, and R. J. Caron. 1998. “Estimating the Prediction Function and the Number of Unseen Species in Sampling with Replacement,” <i class="itshape">Journal of the American Statistical Association</i> 93: 372–79</a>. This discussion adopts the following notation. </p><ul class="itemize">
<li><p><img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" /> is the true population size. </p></li><li><p><img src="images/img-0002.png" alt="$y$" style="vertical-align:-4px; 
                                     width:10px; 
                                     height:13px" class="math gen" /> is the number of samples taken. </p></li><li><p><img src="images/img-0003.png" alt="$x_{k}$" style="vertical-align:-3px; 
                                     width:18px; 
                                     height:12px" class="math gen" /> is the size of the <img src="images/img-0004.png" alt="$k^{th}$" style="vertical-align:0px; 
                                     width:22px; 
                                     height:17px" class="math gen" /> sample. </p></li><li><p><img src="images/img-0005.png" alt="$n$" style="vertical-align:0px; 
                                     width:11px; 
                                     height:9px" class="math gen" /> is the number of distinct entities observed across all samples. </p></li><li><p><img src="images/img-0006.png" alt="$n_{k}$" style="vertical-align:-3px; 
                                     width:19px; 
                                     height:12px" class="math gen" /> is the number of entities observed <img src="images/img-0007.png" alt="$k$" style="vertical-align:0px; 
                                     width:9px; 
                                     height:14px" class="math gen" /> times across all samples, including <img src="images/img-0008.png" alt="$n_{0}$" style="vertical-align:-3px; 
                                     width:19px; 
                                     height:12px" class="math gen" />, which is the number of unobserved entities in the population. </p></li><li><p><img src="images/img-0009.png" alt="$p = \frac{n}{N}$" style="vertical-align:-6px; 
                                     width:52px; 
                                     height:20px" class="math gen" /> is the proportion of the population observed. </p></li>
</ul><h2 id="a0000000002">Cuthbert</h2>
<p>Cuthbert’s method of estimation is a two-stage process that relies on probabilistic reasoning. For the first stage, we momentarily assume that the samples are independent, random, and select from the entire population. Under this assumption, the probability that a given entity will appear in the <img src="images/img-0007.png" alt="$k$" style="vertical-align:0px; 
                                     width:9px; 
                                     height:14px" class="math gen" /><sup>th</sup> sample is <img src="images/img-0010.png" alt="$\frac{x_{k}}{N}$" style="vertical-align:-6px; 
                                     width:16px; 
                                     height:21px" class="math gen" />, and the probability that it will not appear in any sample is the product of the probabilities that it does not appear in each sample: <img src="images/img-0011.png" alt="$\mathbb {P}(unobserved) = \prod _{k=1}^{y}{(1 - \frac{x_{k}}{N})} = \dfrac {\prod _{k=1}^{y}{N - x_{k}}}{N^{y}}$" style="vertical-align:-13px; 
                                     width:407px; 
                                     height:43px" class="math gen" />. Moreover, since under this assumption each of the <img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" /> entities in the population has an identical likelihood of not appearing in any sample, the expected number of unobserved entities is <img src="images/img-0012.png" alt="$E(n_{0}) = N \cdot \mathbb {P}(unobvserved) = \dfrac {\prod _{k=1}^{y}{N - x_{k}}}{N^{y - 1}}$" style="vertical-align:-13px; 
                                     width:381px; 
                                     height:43px" class="math gen" />. And since, by definition, <img src="images/img-0013.png" alt="$n_{0} = N - n$" style="vertical-align:-3px; 
                                     width:98px; 
                                     height:17px" class="math gen" />, an estimate for <img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" /> can be generated by solving for it in the following equation (all parameters other than <img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" /> are known). </p><table id="a0000000003" class="equation" width="100%" cellspacing="0" cellpadding="7">
<tr>
    
    <td style="width:40%">&nbsp;</td>
    <td><img src="images/img-0014.png" alt="\begin{equation}  \frac{\prod _{k=1}^{y}{N - x_{k}}}{N^{y - 1}} - (N - n) = 0 \end{equation}" style="width:241px; 
                            height:43px" class="math gen" /></td>
    
    <td style="width:40%">&nbsp;</td>
    <td class="eqnnum" style="width:20%"><span>(<span>1</span>)</span></td>
</tr>
</table><p>This equation is challenging to solve analytically, since the left-hand side of this expression is largely a ratio of polynomials in <img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" /> of approximate degree <img src="images/img-0002.png" alt="$y$" style="vertical-align:-4px; 
                                     width:10px; 
                                     height:13px" class="math gen" />. However, since the value of <img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" /> is assumed to be a positive integer greater than <img src="images/img-0005.png" alt="$n$" style="vertical-align:0px; 
                                     width:11px; 
                                     height:9px" class="math gen" /> but less than some reasonably large upper bound, and since the left-hand side of the equation is a decreasing function of <img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" />, an approximate solution to this equation can be found relatively expediently via recursive binary search (this is the strategy implemented in <tt class="ttfamily">iceberg.estimate</tt>). This approximate solution is our “initial estimate” of <img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" />, <img src="images/img-0015.png" alt="$\hat{N}_{0}$" style="vertical-align:-3px; 
                                     width:22px; 
                                     height:22px" class="math gen" />. </p><p>In the second stage of Cuthbert’s method, we cross-validate the initial estimate of <img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" /> to test and correct for the assumption that the samples are independent and random. Note that neither the independence nor the randomness of the samples themselves are really being tested here. Rather, we are testing the degree to which the distribution of entities among the samples, <i class="itshape">as a whole</i>, approximates the distribution that would be expected of truly random samples. The process involves first simulating a population of <img src="images/img-0015.png" alt="$\hat{N}_{0}$" style="vertical-align:-3px; 
                                     width:22px; 
                                     height:22px" class="math gen" /> entities that includes every observed entity along with <img src="images/img-0016.png" alt="$\hat{N}_{0} - n$" style="vertical-align:-3px; 
                                     width:58px; 
                                     height:22px" class="math gen" /> “dummy” entities, each representing an unobserved entity. We then randomly choose a number of the original samples to serve as a “validation set,” and note how many entities out of the <img src="images/img-0005.png" alt="$n$" style="vertical-align:0px; 
                                     width:11px; 
                                     height:9px" class="math gen" /> originally observed would not have been observed if those samples had not been collected—call this <img src="images/img-0017.png" alt="$n_{lost}$" style="vertical-align:-3px; 
                                     width:35px; 
                                     height:12px" class="math gen" />. Then construct a “simulated set” of samples by iterating through the validation set and taking truly random samples of identical size from the simulated population (all originally observed entities plus the new dummy entities), and count how many “new” entities are in the simulated set, from the perspective of the corpus of known samples <i class="itshape">not</i> in the validation set—call this <img src="images/img-0018.png" alt="$\hat{n}_{lost}$" style="vertical-align:-3px; 
                                     width:35px; 
                                     height:17px" class="math gen" />. The “error factor” associated with this cross-validation experiment, <img src="images/img-0019.png" alt="$\varepsilon _{i}$" style="vertical-align:-3px; 
                                     width:13px; 
                                     height:12px" class="math gen" />, is then either the extent by which the true number exceeds the simulated number relative to the smaller quantity, or 1 if the simulated number is greater than the true number: <img src="images/img-0020.png" alt="$\varepsilon _{i} = 1 + \max \left( \frac{n_{lost} - \hat{n}_{lost}}{\hat{n}_{lost}}, 0 \right)$" style="vertical-align:-12px; 
                                     width:229px; 
                                     height:36px" class="math gen" />. Restricting <img src="images/img-0021.png" alt="$\varepsilon _{i} \geq 1$" style="vertical-align:-3px; 
                                     width:50px; 
                                     height:17px" class="math gen" /> ensures that cross-validation only increases our ultimate estimates of <img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" /> (or equivalently, that it only decreases our estimates of <img src="images/img-0022.png" alt="$p$" style="vertical-align:-4px; 
                                     width:11px; 
                                     height:13px" class="math gen" />). The “corrected estimate” for cross-validation experiment <img src="images/img-0023.png" alt="$i$" style="vertical-align:0px; 
                                     width:6px; 
                                     height:13px" class="math gen" />, <img src="images/img-0024.png" alt="$\hat{N}_{i}$" style="vertical-align:-3px; 
                                     width:19px; 
                                     height:22px" class="math gen" />, is then: </p><table id="a0000000004" class="equation" width="100%" cellspacing="0" cellpadding="7">
<tr>
    
    <td style="width:40%">&nbsp;</td>
    <td><img src="images/img-0025.png" alt="\begin{equation}  \hat{N}_{i} = n + \varepsilon _{i} \left( \hat{N}_{0} - n \right) \end{equation}" style="width:181px; 
                            height:36px" class="math gen" /></td>
    
    <td style="width:40%">&nbsp;</td>
    <td class="eqnnum" style="width:20%"><span>(<span>2</span>)</span></td>
</tr>
</table><p>The resultant distribution of <img src="images/img-0026.png" alt="$\{ \hat{N}_{i}\} $" style="vertical-align:-5px; 
                                     width:39px; 
                                     height:24px" class="math gen" /> across a sufficiently large number of cross-validation experiments then indicate something about the stability of <img src="images/img-0027.png" alt="$\hat{N}$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:19px" class="math gen" /> for a given population—which is to say, the sensitivity of this estimate to non-randomness in the samples. More specifically, while the definition of the error factors ensures that most (if not all) distributions of <img src="images/img-0026.png" alt="$\{ \hat{N}_{i}\} $" style="vertical-align:-5px; 
                                     width:39px; 
                                     height:24px" class="math gen" /> will exhibit some leftward skew, the relative severity of this skew can still indicate whether the estimate is comparatively stable or unstable. </p><h2 id="a0000000005">Boneh, Boneh, and Caron (BBC)</h2>
<p>The second method, proposed by BBC, is completely different in its motivation and execution. the authors begin by considering a multinomial distribution, describing the outcome of sampling from <img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" /> objects with replacement and with probabilities <img src="images/img-0028.png" alt="$p_{1}, \ldots ,p_{N}$" style="vertical-align:-4px; 
                                     width:84px; 
                                     height:13px" class="math gen" />. They then observe that this is related in the limit to a scenario in which there are <img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" /> independent Poisson processes with parameters <img src="images/img-0029.png" alt="$\lambda _{1},\ldots ,\lambda _{N}$" style="vertical-align:-4px; 
                                     width:85px; 
                                     height:18px" class="math gen" />. The relation is fairly transparent: if we track these Poisson processes in the interval <img src="images/img-0030.png" alt="$[0, 1]$" style="vertical-align:-5px; 
                                     width:36px; 
                                     height:20px" class="math gen" /> and count how many of them occur once, how many occur twice, etc., then this is identical to generating values for <img src="images/img-0031.png" alt="$\{ n_{1}, n_{2},\ldots n_{m}\} $" style="vertical-align:-5px; 
                                     width:125px; 
                                     height:20px" class="math gen" />, where <img src="images/img-0032.png" alt="$m$" style="vertical-align:0px; 
                                     width:17px; 
                                     height:9px" class="math gen" /> is the maximum number of times that any individual Poisson process is detected. </p><p>In order to use this information to estimate the total number of Poisson processes, <img src="images/img-0001.png" alt="$N$" style="vertical-align:0px; 
                                     width:16px; 
                                     height:14px" class="math gen" />, it is useful to define the auxiliary function <img src="images/img-0033.png" alt="$D(t)$" style="vertical-align:-5px; 
                                     width:36px; 
                                     height:20px" class="math gen" /> to be the number of processes detected in the interval <img src="images/img-0034.png" alt="$(1, t+1]$" style="vertical-align:-5px; 
                                     width:69px; 
                                     height:20px" class="math gen" /> that were not first detected in the interval <img src="images/img-0030.png" alt="$[0, 1]$" style="vertical-align:-5px; 
                                     width:36px; 
                                     height:20px" class="math gen" />, and the function <img src="images/img-0035.png" alt="$\Psi (t) = E(D(t))$" style="vertical-align:-5px; 
                                     width:131px; 
                                     height:20px" class="math gen" />, which BBC call “the prediction function.” <img src="images/img-0036.png" alt="$\Psi (t)$" style="vertical-align:-5px; 
                                     width:35px; 
                                     height:20px" class="math gen" /> has several attractive mathematical properties, including that it has infinite order alternating copositivity (that is, its <img src="images/img-0007.png" alt="$k$" style="vertical-align:0px; 
                                     width:9px; 
                                     height:14px" class="math gen" /><sup>th</sup> derivative takes positive values on the positive half-line for all odd <img src="images/img-0007.png" alt="$k$" style="vertical-align:0px; 
                                     width:9px; 
                                     height:14px" class="math gen" /> and negative values for all even <img src="images/img-0007.png" alt="$k$" style="vertical-align:0px; 
                                     width:9px; 
                                     height:14px" class="math gen" />) and that it is bounded, which together mean that it has an asymptotic limit as <img src="images/img-0037.png" alt="$t$" style="vertical-align:0px; 
                                     width:7px; 
                                     height:13px" class="math gen" /> increases. Computing this limit is tantamount to generating an estimate for <img src="images/img-0008.png" alt="$n_{0}$" style="vertical-align:-3px; 
                                     width:19px; 
                                     height:12px" class="math gen" />. </p><p>BBC also show that this limit may be estimated with a relatively simple two-part process. First, calculate a biased estimate, <img src="images/img-0038.png" alt="$\hat{\Psi }(\infty )$" style="vertical-align:-5px; 
                                     width:48px; 
                                     height:24px" class="math gen" />, using a simple sum of exponentials: </p><table id="a0000000006" class="equation" width="100%" cellspacing="0" cellpadding="7">
<tr>
    
    <td style="width:40%">&nbsp;</td>
    <td><img src="images/img-0039.png" alt="\begin{equation}  \hat{\Psi }(\infty ) = \sum _{k = 1}^{m}{n_{k}e^{-k}} \end{equation}" style="width:155px; 
                            height:54px" class="math gen" /></td>
    
    <td style="width:40%">&nbsp;</td>
    <td class="eqnnum" style="width:20%"><span>(<span>3</span>)</span></td>
</tr>
</table><p> An unbiased estimate, <img src="images/img-0040.png" alt="$\hat{n}_{0}$" style="vertical-align:-3px; 
                                     width:19px; 
                                     height:17px" class="math gen" />, can then be obtained by numerically solving the equation: </p><table id="a0000000007" class="equation" width="100%" cellspacing="0" cellpadding="7">
<tr>
    
    <td style="width:40%">&nbsp;</td>
    <td><img src="images/img-0041.png" alt="\begin{equation}  \hat{n}_{0}\left(1 - e^{\frac{-n_{1}}{\hat{n}_{0}}}\right) = \hat{\Psi }(\infty ) \end{equation}" style="width:194px; 
                            height:36px" class="math gen" /></td>
    
    <td style="width:40%">&nbsp;</td>
    <td class="eqnnum" style="width:20%"><span>(<span>4</span>)</span></td>
</tr>
</table><p> BBC also give some details for how this equation may be efficiently solved via numerical methods; <tt class="ttfamily">iceberg.estimate</tt> utilizes their algorithm. </p></div>





<div class="navigation">
<table cellspacing="2" cellpadding="0" width="100%">
<tr>

<td><img border="0" alt="" src="icons/blank.gif" width="32" height="32" /></td>

<td><img border="0" alt="" src="icons/blank.gif" width="32" height="32" /></td>

<td><img border="0" alt="" src="icons/blank.gif" width="32" height="32" /></td>
<td class="navtitle" align="center">Estimation Algorithms</td>
<td><a href="index.html" title="Table of Contents"><img border="0" alt="" src="icons/contents.gif" width="32" height="32" /></a></td>


<td><img border="0" alt="" src="icons/blank.gif" width="32" height="32" /></td>
<td><img border="0" alt="" src="icons/blank.gif" width="32" height="32" /></td>
</tr>
</table>
</div>

</body>
</html>